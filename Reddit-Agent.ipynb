{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reddit GenAI Trend Analysis with ReAct Agent Framework\n",
    "\n",
    "Author: Amanda Milberg, Principal Solutions Engineer @ Doubleword\n",
    "\n",
    "üéØ **Main Purpose**:\n",
    "- Analyzes r/technology subreddit posts to identify and summarize GenAI-related content\n",
    "- Generates professional summaries of AI trends and developments to send to downstream users who want to stay up to date on the latest trends\n",
    "\n",
    "üîë **Key Components**:\n",
    "1. Reddit API Integration to scrape relevant posts in a given subreddit (e.g. r/technology)\n",
    "2. LLM-powered analysis to:\n",
    "   - Determine GenAI relevance based on the thread title\n",
    "   - Summarize key themes and content for each article\n",
    "   - Generate trend analysis summary reports for all the GenAI related articles \n",
    "\n",
    "üìä **Process Flow**:\n",
    "1. Fetches hot posts from r/technology \n",
    "2. Filters for GenAI-related content\n",
    "3. Extracts and summarizes article content\n",
    "4. Creates comprehensive trend analysis\n",
    "5. Generates formatted report with sources ready to email to downstream users \n",
    "\n",
    "üõ†Ô∏è **Technologies Used**:\n",
    "- PRAW (Reddit API)\n",
    "- OpenAI API/Self-hosted LLM\n",
    "- BeautifulSoup for web scraping\n",
    "- Markdown for report formatting\n",
    "- ReAct agent framework\n",
    "\n",
    "_Note: Requires Reddit API credentials and access to a LLM to function._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Use an Agent Framework?\n",
    "\n",
    "- Implements the ReAct (Reasoning + Acting) paradigm for more transparent and controlled AI behavior\n",
    "- Provides explicit thinking and action steps for complex tasks\n",
    "- Enables better debugging and monitoring of the AI's decision process\n",
    "\n",
    "üß† **ReAct Framework Benefits**:\n",
    "1. **Reasoning Transparency**\n",
    "   - Agent explicitly shows its thinking process before actions\n",
    "   - Helps track decision-making logic\n",
    "   - Makes debugging easier\n",
    "\n",
    "2. **Structured Actions**\n",
    "   - Clear separation between thinking and execution\n",
    "   - Each action has defined inputs and outputs\n",
    "   - Better error handling and recovery\n",
    "\n",
    "3. **Process Monitoring**\n",
    "   - Logs each step of the analysis pipeline\n",
    "   - Tracks success/failure of individual components\n",
    "   - Maintains history of decisions and actions\n",
    "\n",
    "_The agent framework transforms what could be a simple script into a more robust, observable, and maintainable system for AI analysis. The agent approach provides better structure, transparency, and reliability for complex AI tasks compared to a simple main function._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why Self-Host?\n",
    "\n",
    "üåü **Key Benefits of Self-Hosting** \n",
    "\n",
    "1. **Cost-Effective Performance**\n",
    "   - Reduced operational costs for high-volume processing\n",
    "   - No ongoing API fees or usage limits\n",
    "\n",
    "2. **Privacy & Data Control** \n",
    "   - Complete control over data processing and storage\n",
    "   - No data sharing with external providers\n",
    "   - Compliance with internal security policies\n",
    "   - Ability to air-gap for sensitive applications & sensitive data \n",
    "\n",
    "3. **Deployment Flexibility**\n",
    "   - Run locally on your own infrastructure\n",
    "   - Scale resources based on actual needs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why Deep Seek?\n",
    "\n",
    "1. **Specialized Reasoning Capabilities**\n",
    "   - Optimized for logical reasoning and analysis tasks\n",
    "   - Efficient chain-of-thought processing\n",
    "   - Ideal for structured analytical workflows\n",
    "2. **Open Source Technology + Self-Hosting Stack = üòç**  \n",
    "   - Deepseek broke the internet \n",
    "   - Firm believer in owning your AI stack \n",
    "   - Smaller / specalized models for a given application  \n",
    "\n",
    "_Note: In this demo we are running a self-hosted [DeepSeek-R1-Distill-Llama-8B](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B) deployed on 4xL4 GPUs using the [TitanML's Takeoff Stack](https://docs.titanml.co/). If you want to try this on your own you can pull this repository and swap in an OpenAI model. The code uses OpenAI compatiable endpoints so any model should be able to be swapped in. If you have any questions please reach out to: amanda.milberg@titanml.co_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions in AI Agent Architecture (or the \"Doing\")\n",
    "\n",
    "üîß **Service Functions**\n",
    "Functions that handle specific, specialized tasks like:\n",
    "- API interactions (init_reddit, init_llm)\n",
    "- Web scraping (extract_article_content)\n",
    "- Data parsing & formatting (parse_llm_response)\n",
    "- LLM analysis (analyze_genai_relevance, summarize_content, create_email_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import os\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Optional\n",
    "from openai import OpenAI\n",
    "from bs4 import BeautifulSoup\n",
    "import json \n",
    "import re\n",
    "import requests\n",
    "from IPython.display import display, Markdown, HTML\n",
    "\n",
    "\n",
    "def init_reddit(client_id: str, client_secret: str, user_agent: str) -> praw.Reddit:\n",
    "    \"\"\"Initialize Reddit API client\"\"\"\n",
    "    return praw.Reddit(\n",
    "        client_id=client_id,\n",
    "        client_secret=client_secret,\n",
    "        user_agent=user_agent\n",
    "    )\n",
    "\n",
    "def init_llm(api_key: str) -> OpenAI:\n",
    "    ## For practice at home, you can sub the self-hosted LLM for openAI LLM\n",
    "    \"\"\"Initialize OpenAI LLM Note: Need access to OpenAI Key\n",
    "    os.environ['OPENAI_API_KEY'] = api_key\n",
    "    client = OpenAI(temperature=0.7)\n",
    "    \"\"\"\n",
    "    ## In our demo we will use a self-hosted LLM deployed with Titan Takeoff Stack\n",
    "    client = OpenAI(\n",
    "    base_url=\"<YOUR_ENDPOINT>\n",
    "    api_key=\"not needed\"\n",
    "    )\n",
    "\n",
    "    return client\n",
    "\n",
    "\n",
    "def extract_article_content(url: str) -> str:\n",
    "    \"\"\"Extract main content from article URL with proper headers\"\"\"\n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "            'Accept-Language': 'en-US,en;q=0.5',\n",
    "            'Connection': 'keep-alive',\n",
    "        }\n",
    "        \n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()  # Raise exception for bad status codes\n",
    "        \n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        for script in soup([\"script\", \"style\"]):\n",
    "            script.decompose()\n",
    "        text = soup.get_text(separator=' ', strip=True)\n",
    "        return ' '.join(text.split())\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting content: {str(e)}\")\n",
    "        return \"\"\n",
    "\n",
    "def analyze_genai_relevance(llm: OpenAI, title: str) -> dict:\n",
    "    \"\"\"Analyze if title is GenAI-related using LLM\"\"\"\n",
    "\n",
    "    system_prompt = \"\"\"You are a helpful AI assistant. Based on the title \n",
    "    of the article provide a suggestion if this content relates to Generative AI:\n",
    "    \n",
    "    Return JSON:\n",
    "        {{\n",
    "            \"is_genai_related\": true/false,\n",
    "            \"relevance_type\": \"direct/indirect/none\",\n",
    "        }}\"\"\"    \n",
    "    try:\n",
    "        response = llm.chat.completions.create(\n",
    "            model = \"deepseek-r1\", ##switch to OpenAI model (e.g. gpt-4) for OpenAI implementation \n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": title}\n",
    "            ],\n",
    "            max_tokens = 2000\n",
    "        )\n",
    "        \n",
    "        # Extract the response content\n",
    "        response_dict = parse_llm_response(response.choices[0].message.content)\n",
    "        return response_dict\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in GenAI relevance: {str(e)}\")\n",
    "        return \"\"\n",
    "    \n",
    "def parse_llm_response(response_text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Parse LLM response to separate thinking process and JSON response from \n",
    "    analyze_genai_relevance()\n",
    "    \"\"\"\n",
    "    # Pattern for think tags\n",
    "    think_pattern = r'<think>(.*?)</think>'\n",
    "    \n",
    "    # Pattern for JSON (anything between triple backticks and json)\n",
    "    json_pattern = r'```json\\n(.*?)```'\n",
    "    \n",
    "    # Extract thinking process\n",
    "    thinking = re.search(think_pattern, response_text, re.DOTALL)\n",
    "    thinking = thinking.group(1).strip() if thinking else \"\"\n",
    "    \n",
    "    # Extract JSON response\n",
    "    json_match = re.search(json_pattern, response_text, re.DOTALL)\n",
    "    json_str = json_match.group(1).strip() if json_match else \"{}\"\n",
    "    json_data = json.loads(json_str)\n",
    "    \n",
    "    return {\n",
    "        \"thinking\": thinking,\n",
    "        \"response\": json_data\n",
    "    }\n",
    "\n",
    "\n",
    "def summarize_content(llm: OpenAI, content: str) -> str:\n",
    "    \"\"\"\n",
    "    Summarize input text using the chat completions model directly\n",
    "    \"\"\"\n",
    "    system_prompt = \"\"\"You are a helpful AI assistant. Given a piece of text, analyze its content and provide a concise summary.\n",
    "    Focus on extracting key information and main ideas.\n",
    "    If the text contains technical terms, explain them in simple language.\n",
    "    Format your response in a clear, organized manner.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = llm.chat.completions.create(\n",
    "            model = \"deepseek-r1\", ##switch to OpenAI model (e.g. gpt-4) for OpenAI implementation\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": content}\n",
    "            ],\n",
    "            max_tokens = 2000\n",
    "        )\n",
    "        \n",
    "        # Parse the response content\n",
    "        response_summary_dict = parse_llm_summary(response.choices[0].message.content)\n",
    "\n",
    "        return response_summary_dict\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in summarization: {str(e)}\")\n",
    "        return \"\"\n",
    "\n",
    "def parse_llm_summary(response_text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Parse LLM response to separate thinking process and summary after \n",
    "    summarize_content()\n",
    "    \"\"\"\n",
    "    # Pattern for think tags\n",
    "    think_pattern = r'<think>(.*?)</think>'\n",
    "    \n",
    "    # Extract thinking process (everything between think tags)\n",
    "    thinking = re.search(think_pattern, response_text, re.DOTALL)\n",
    "    thinking = thinking.group(1).strip() if thinking else \"\"\n",
    "    \n",
    "    # Get summary (everything after </think>)\n",
    "    summary = re.split(r'</think>\\s*', response_text)[-1].strip()\n",
    "    \n",
    "    return {\n",
    "        \"thinking\": thinking,\n",
    "        \"summary\": summary\n",
    "    }\n",
    "\n",
    "\n",
    "def get_reddit_trends(reddit: praw.Reddit, llm: OpenAI, limit: int = 20) -> List[Dict]:\n",
    "    \"\"\"Fetch and analyze Reddit trends\"\"\"\n",
    "    trends = []\n",
    "    print(f\"üéØ ACTION: Fetching {limit} most popular threads:\")\n",
    "    print(\"=\" * 50)\n",
    "    for submission in reddit.subreddit('technology').hot(limit=limit):\n",
    "        content = extract_article_content(submission.url) or submission.selftext\n",
    "        print(submission.title)\n",
    "        relevance = analyze_genai_relevance(llm, submission.title)\n",
    "        print(f\"GenAI Relevance: {relevance['response']['is_genai_related']}\")\n",
    "        if relevance['response']['is_genai_related']:\n",
    "            print(f\"üéØ ACTION: üìñ Reading Article Details at {submission.url}\")\n",
    "            llm_summary = summarize_content(llm, content) if content else None\n",
    "            trends.append({\n",
    "                'title': submission.title,\n",
    "                'subreddit': submission.subreddit.display_name,\n",
    "                'score': submission.score,\n",
    "                'comments': submission.num_comments,\n",
    "                'url': submission.url,\n",
    "                'relevance': relevance,\n",
    "                'summary': llm_summary['summary']\n",
    "            })\n",
    "        print(\"=\" * 50)\n",
    "    return trends\n",
    "\n",
    "\n",
    "def create_email_summary(trends_list: list, llm: OpenAI) -> str:\n",
    "    \"\"\"\n",
    "    Create an email-style summary from a structured trends dictionary\n",
    "    \"\"\"\n",
    "    # First, let's format the trends data into a more digestible format for the model\n",
    "    formatted_input = \"Recent AI Trends Analysis:\\n\\n\"\n",
    "    for trend in trends_list:\n",
    "        formatted_input += f\"Title: {trend['title']}\\n\"\n",
    "        formatted_input += f\"Engagement: {trend['score']} points, {trend['comments']} comments\\n\"\n",
    "        formatted_input += f\"Summary: {trend['summary']}\\n\\n\"\n",
    "\n",
    "    system_prompt = \"\"\"You are an AI analyst creating clear, professional  summaries of AI news and trends. \n",
    "    Analyze the provided structured data about AI trends and create a well-organized summary that covers:\n",
    "\n",
    "    1. Main Technologies Discussed\n",
    "    - Extract and categorize key AI technologies mentioned across all trends\n",
    "    - Focus on technical implementations and capabilities\n",
    "\n",
    "    2. Key Trends\n",
    "    - Synthesize patterns across all articles\n",
    "    - Identify emerging themes and industry movements\n",
    "    - Include relevant metrics and engagement data\n",
    "\n",
    "    3. Public Sentiment\n",
    "    - Analyze reactions based on comments and scoring\n",
    "    - Note any controversial or highly-engaged topics\n",
    "    - Identify areas of public concern or interest\n",
    "\n",
    "    4. Notable Developments\n",
    "    - Highlight significant announcements or findings\n",
    "    - Include specific numbers, statistics, or metrics\n",
    "    - Note any regulatory or policy changes\n",
    "\n",
    "    Format your response as a professional summary with clear headers and bullet points.\n",
    "    Use engagement metrics (score and comments) to help gauge importance of different topics.\"\"\"\n",
    "    try:\n",
    "        response = llm.chat.completions.create(\n",
    "            model = \"deepseek-r1\", ##switch to OpenAI model (e.g. gpt-4) for OpenAI implementation\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": formatted_input}\n",
    "            ],\n",
    "            max_tokens = 2000\n",
    "        )\n",
    "        llm_response = response.choices[0].message.content\n",
    "\n",
    "        # Split Thinking\n",
    "        end_think_pos = llm_response.find('</think>')\n",
    "        thinking_response = llm_response[:end_think_pos]\n",
    "        summary = llm_response[end_think_pos+9:]\n",
    "        f_thinking_response = \"### Deepseek Reasoning\\n\\n\" + thinking_response + \"\\n\\n---\\n\\n\"\n",
    "\n",
    "        \n",
    "        # Add Further Reading section\n",
    "        further_reading = \"\\n\\n---\\n\\n### Further Reading\\n\\n\"\n",
    "        for trend in trends_list:\n",
    "            further_reading += f\"**{trend['title']}**\\n\"\n",
    "            further_reading += f\"- Source: {trend['url']}\\n\\n\"\n",
    "\n",
    "        # Combine AI analysis with Further Reading\n",
    "        complete_email = f_thinking_response + summary + further_reading\n",
    "        \n",
    "        return display(Markdown(complete_email))\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in trends summarization: {str(e)}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI Agent (the Orchestrator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RedditAIAnalysisAgent:\n",
    "    def __init__(self, reddit_creds: dict, openai_api_key: str):\n",
    "        self.reddit_creds = reddit_creds\n",
    "        self.openai_api_key = openai_api_key\n",
    "        self.reddit = None\n",
    "        self.llm = None\n",
    "        self.thought_history = []\n",
    "        print(\"\\nü§ñ Initializing Reddit AI Analysis Agent...\\n\")\n",
    "        \n",
    "    def think(self, thought: str):\n",
    "        \"\"\"Record agent's thinking process\"\"\"\n",
    "        self.thought_history.append({\"thought\": thought, \"timestamp\": datetime.now().isoformat()})\n",
    "        print(f\"\\nü§î THINKING: {thought}\")\n",
    "        \n",
    "    def act(self, action: str, result: any):\n",
    "        \"\"\"Record agent's actions and results\"\"\"\n",
    "        self.thought_history.append({\n",
    "            \"action\": action,\n",
    "            \"result\": result,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        })\n",
    "        print(f\"üéØ ACTION: {action}\")\n",
    "        print(f\"üìù RESULT: {result}\\n\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "    def initialize_clients(self) -> bool:\n",
    "        \"\"\"Initialize Reddit and LLM clients\"\"\"\n",
    "        try:\n",
    "            print(\"\\nüì° INITIALIZING CLIENTS...\")\n",
    "            self.think(\"Need to initialize Reddit and LLM client\")\n",
    "            \n",
    "            self.reddit = init_reddit(\n",
    "                self.reddit_creds['client_id'],\n",
    "                self.reddit_creds['client_secret'],\n",
    "                self.reddit_creds['user_agent']\n",
    "            )\n",
    "            self.act(\"Initialize Reddit client\", \"‚úÖ Reddit client initialized successfully\")\n",
    "            \n",
    "            self.llm = init_llm(self.openai_api_key)\n",
    "            self.act(\"Initialize LLM client\", \"‚úÖ LLM client initialized successfully. DeepSeek-R1-Distill-Llama-8B running on 4xL4 Machine\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.act(\"Initialize clients\", f\"‚ùå Failed: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "    def analyze_trends(self) -> Optional[Dict]:\n",
    "        \"\"\"Get and analyze Reddit trends\"\"\"\n",
    "        try:\n",
    "            print(\"\\nüîç ANALYZING REDDIT TRENDS...\")\n",
    "            self.think(\"Fetching Reddit trends for analysis\")\n",
    "            \n",
    "            # Get trends\n",
    "            print(\"\\nüìä Fetching posts from r/technology...\")\n",
    "            trends = get_reddit_trends(self.reddit, self.llm)\n",
    "            \n",
    "            if not trends:\n",
    "                self.think(\"No GenAI trends found in current batch\")\n",
    "                self.act(\"Analyze trends\", \"‚ö†Ô∏è No relevant trends found\")\n",
    "                return {\n",
    "                    \"success\": True,\n",
    "                    \"timestamp\": datetime.now().isoformat(),\n",
    "                    \"analysis\": \"No GenAI trends found.\",\n",
    "                    \"trends\": [],\n",
    "                    \"count\": 0\n",
    "                }\n",
    "            \n",
    "            # Log initial processing\n",
    "            print(f\"‚úÖ Summarization complete for {len(trends)} trends\")\n",
    "            \n",
    "            self.think(f\"Creating high level email summary for overall GenAI trends found\")\n",
    "            analysis = create_email_summary(trends, self.llm)\n",
    "            \n",
    "            # Log completion without printing details\n",
    "            self.act(\"Create analysis\", f\"‚úÖ Analysis complete for {len(trends)} trends\")\n",
    "            \n",
    "            return {\n",
    "                \"success\": True,\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"analysis\": analysis,\n",
    "                \"trends\": trends,\n",
    "                \"count\": len(trends),\n",
    "                \"thought_process\": self.thought_history\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.act(\"Analyze trends\", f\"‚ùå Failed: {str(e)}\")\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": str(e),\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"thought_process\": self.thought_history\n",
    "            }\n",
    "\n",
    "    def run(self) -> Dict:\n",
    "        \"\"\"Main execution flow with ReAct framework\"\"\"\n",
    "        print(\"\\nüöÄ STARTING REDDIT AI TREND ANALYSIS\\n\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        self.think(\"Starting Reddit AI trend analysis\")\n",
    "        \n",
    "        # Initialize clients\n",
    "        if not self.initialize_clients():\n",
    "            print(\"\\n‚ùå Failed to initialize clients. Aborting...\")\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": \"Failed to initialize clients\",\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"thought_process\": self.thought_history\n",
    "            }\n",
    "        \n",
    "        # Analyze trends\n",
    "        result = self.analyze_trends()\n",
    "        \n",
    "        if result[\"success\"]:\n",
    "            self.think(\"Analysis complete, final report generated\")\n",
    "            print(\"\\n‚úÖ ANALYSIS COMPLETE\")\n",
    "            print(\"=\" * 50)\n",
    "            print(\"\\nFinal report has been generated in the response.\")\n",
    "        else:\n",
    "            print(\"\\n‚ùå Analysis failed. Check error details.\")\n",
    "        \n",
    "        return result\n",
    "\n",
    "def main(reddit_creds: dict, openai_api_key: str) -> dict:\n",
    "    \"\"\"Main function using ReAct agent\"\"\"\n",
    "    agent = RedditAIAnalysisAgent(reddit_creds, openai_api_key)\n",
    "    return agent.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Live Demo Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Initializing Reddit AI Analysis Agent...\n",
      "\n",
      "\n",
      "üöÄ STARTING REDDIT AI TREND ANALYSIS\n",
      "\n",
      "==================================================\n",
      "\n",
      "ü§î THINKING: Starting Reddit AI trend analysis\n",
      "\n",
      "üì° INITIALIZING CLIENTS...\n",
      "\n",
      "ü§î THINKING: Need to initialize Reddit and LLM client\n",
      "üéØ ACTION: Initialize Reddit client\n",
      "üìù RESULT: ‚úÖ Reddit client initialized successfully\n",
      "\n",
      "==================================================\n",
      "üéØ ACTION: Initialize LLM client\n",
      "üìù RESULT: ‚úÖ LLM client initialized successfully. DeepSeek-R1-Distill-Llama-8B running on 4xL4 Machine\n",
      "\n",
      "==================================================\n",
      "\n",
      "üîç ANALYZING REDDIT TRENDS...\n",
      "\n",
      "ü§î THINKING: Fetching Reddit trends for analysis\n",
      "\n",
      "üìä Fetching posts from r/technology...\n",
      "üéØ ACTION: Fetching 20 most popular threads:\n",
      "==================================================\n",
      "Disney+ Lost 700,000 Subscribers from October-December\n",
      "GenAI Relevance: False\n",
      "==================================================\n",
      "USAID Was Investigating Starlink Over Its Contracts in Ukraine | The agency was in the midst of a probe into the billionaire's company at the time of the assault.\n",
      "GenAI Relevance: False\n",
      "==================================================\n",
      "Reddit community banned as user spat with Musk intensifies - BBC News\n",
      "GenAI Relevance: False\n",
      "==================================================\n",
      "Treasury tells Congress that DOGE has ‚ÄòRead Only‚Äô access to payment systems\n",
      "GenAI Relevance: False\n",
      "==================================================\n",
      "DeepSeek users could face million-dollar fine and prison time under new law\n",
      "GenAI Relevance: True\n",
      "üéØ ACTION: üìñ Reading Article Details at https://www.the-independent.com/tech/deepseek-ai-us-ban-prison-b2692396.html\n",
      "==================================================\n",
      "Teslas turn toxic as sales crash in Europe and the UK\n",
      "GenAI Relevance: False\n",
      "==================================================\n",
      "USPS Halts All Packages From China, Sending the Ecommerce Industry Into Chaos\n",
      "GenAI Relevance: False\n",
      "==================================================\n",
      "Tesla Sales Plunge 59% in Germany to Lowest Level in Years\n",
      "GenAI Relevance: False\n",
      "==================================================\n",
      "Reddit temporarily bans r/WhitePeopleTwitter after Elon Musk claimed it had ‚Äòbroken the law‚Äô\n",
      "GenAI Relevance: False\n",
      "==================================================\n",
      "Error extracting content: 403 Client Error: Forbidden for url: https://www.nytimes.com/2025/02/04/business/usps-china-de-minimis.html?smid=nytcore-ios-share&referringSource=articleShare\n",
      "U.S. Postal Service Reverses Decision to Halt Parcel Service From China\n",
      "GenAI Relevance: False\n",
      "==================================================\n",
      "Google removes pledge to not use AI for weapons from website\n",
      "GenAI Relevance: False\n",
      "==================================================\n",
      "As the Trump admin deletes online data, scientists and digital librarians rush to save it\n",
      "GenAI Relevance: False\n",
      "==================================================\n",
      "Internet Archive played crucial role in tracking shady CDC data removals | Internet Archive makes it easier to track changes in CDC data online.\n",
      "GenAI Relevance: False\n",
      "==================================================\n",
      "Cybersecurity, government experts are aghast at security failures in DOGE takeover\n",
      "GenAI Relevance: False\n",
      "==================================================\n",
      "Why Mark Zuckerberg wants to redefine open source so badly\n",
      "GenAI Relevance: False\n",
      "==================================================\n",
      "Russian army hit by mass Starlink outages on Ukraine frontline\n",
      "GenAI Relevance: False\n",
      "==================================================\n",
      "Will TikTok Be Banned Again? Tech Giants Could Face $850 Billion In Potential Fines As Trump‚Äôs Grace Period Creates Uncertainty\n",
      "GenAI Relevance: False\n",
      "==================================================\n",
      "DOGE Employees Ordered to Stop Using Slack While Agency Transitions to Records System That Is Not Subject to FOIA\n",
      "GenAI Relevance: False\n",
      "==================================================\n",
      "Workers at NASA Told to ‚ÄòDrop Everything‚Äô to Scrub Mentions of Indigenous People, Women from Its Websites | \"This is a drop everything and reprioritize your day request,\" a directive \"per NASA HQ direction\" stated.\n",
      "GenAI Relevance: False\n",
      "==================================================\n",
      "Federal Workers Sue to Disconnect DOGE Server\n",
      "GenAI Relevance: False\n",
      "==================================================\n",
      "‚úÖ Summarization complete for 1 trends\n",
      "\n",
      "ü§î THINKING: Creating high level email summary for overall GenAI trends found\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Deepseek Reasoning\n",
       "\n",
       "<think>\n",
       "Okay, so I need to create a professional summary of recent AI trends based on the provided structured data. The user has given me a specific query where they want me to analyze the data and cover four main areas: Main Technologies, Key Trends, Public Sentiment, and Notable Developments. They also provided an example response, which I can use as a reference for the structure and style.\n",
       "\n",
       "First, I'll start by understanding the data. The main article is about DeepSeek, a Chinese AI app that's become popular in the US, leading to concerns and a proposed law. The engagement is high with 3651 points and 686 comments, indicating it's a hot topic.\n",
       "\n",
       "For the Main Technologies section, I need to extract and categorize the key AI technologies mentioned. From the example, they focused on AI-driven search engines and data analytics. I should make sure to include these and perhaps any other relevant technologies mentioned, like data storage or algorithms.\n",
       "\n",
       "Next, Key Trends. The example identified several trends: rise of AI search engines, geopolitical tensions, regulatory scrutiny, and ethical concerns. I should look for patterns in the data that support these trends. The high engagement suggests that the rise of DeepSeek and the proposed law are significant trends.\n",
       "\n",
       "Moving on to Public Sentiment. The example analyzed reactions, noting concerns about data security and national interests, as well as debates over regulation and innovation. I should consider the comments and scoring to gauge sentiment. Since the engagement is high, there's likely a lot of discussion around these issues, which I can summarize.\n",
       "\n",
       "For Notable Developments, the example highlighted the proposed law with specific penalties, government bans, and expert warnings. I should include any significant announcements, numbers, or policy changes. The fines and imprisonment terms are key points here.\n",
       "\n",
       "I also need to ensure the summary is well-organized with clear headers and bullet points, as per the user's instructions. The language should be professional and concise, avoiding any markdown formatting.\n",
       "\n",
       "I should also make sure each section is concise but comprehensive, covering all the necessary points without being too verbose. Using the example as a guide, I can structure each section with bullet points under each main category.\n",
       "\n",
       "I might need to infer some information if the data isn't explicitly provided, but I should stay true to the information given. For instance, while the example mentioned ethical limitations, the provided data didn't go into detail, so I should be cautious not to overstate that part.\n",
       "\n",
       "Finally, I'll conclude the summary by tying together the main points, emphasizing the intersection of technology, security, and international relations, and the impact of the proposed law on US interests and global tech dynamics.\n",
       "\n",
       "I think I've covered all the necessary parts. Now, I'll structure the summary accordingly, making sure each section flows logically and covers all the required aspects.\n",
       "\n",
       "\n",
       "---\n",
       "\n",
       "\n",
       "### Recent AI Trends Analysis: DeepSeek and Geopolitical Implications\n",
       "\n",
       "---\n",
       "\n",
       "#### **1. Main Technologies Discussed**\n",
       "- **AI-Driven Search Engines**: DeepSeek leverages advanced AI algorithms to provide intelligent search capabilities, competing with traditional search engines.\n",
       "- **Data Analytics**: The app processes vast amounts of user data, raising concerns about data privacy and security.\n",
       "- **Cloud-Based Services**: DeepSeek's reliance on Chinese-based servers highlights issues related to data storage and access.\n",
       "\n",
       "---\n",
       "\n",
       "#### **2. Key Trends**\n",
       "- **Rise of AI-Driven Search Platforms**: DeepSeek's popularity in the U.S. underscores the growing influence of Chinese AI technologies in global markets.\n",
       "- **Geopolitical Tensions in AI Development**: The U.S. is increasingly scrutinizing Chinese AI advancements, reflecting broader international competition in the tech sector.\n",
       "- **Heightened Regulatory Scrutiny**: The proposed legislation targeting Chinese AI companies signals a shift toward stricter regulations on foreign tech products.\n",
       "- **Public Concern Over Data Security**: Users and experts are expressing worries about data privacy and potential misuse of personal information.\n",
       "\n",
       "---\n",
       "\n",
       "#### **3. Public Sentiment**\n",
       "- **Concerns About National Security**: Many comments highlight fears of Chinese data harvesting and potential infiltration of critical U.S. infrastructure.\n",
       "- **Debate Over Regulation vs. Innovation**: Public opinion is divided on whether the proposed law will protect national interests or stifle technological progress.\n",
       "- **Focus on User Privacy**: There is significant engagement on the ethical implications of using AI tools that store data in foreign countries.\n",
       "\n",
       "---\n",
       "\n",
       "#### **4. Notable Developments**\n",
       "- **Proposed Law**: Republican Senator Josh Hawley's bill aims to prohibit U.S. persons from aiding China's AI advancements, with severe penalties for violations, including fines up to $100 million for businesses and $1 million for individuals, and up to 20 years in prison.\n",
       "- **Government Bans**: The U.S. Navy, NASA, and the state of Texas have banned DeepSeek on government devices, citing security risks.\n",
       "- **Expert Warnings**: Security experts have raised concerns that DeepSeek poses a greater threat than other Chinese apps like TikTok due to its data storage practices.\n",
       "\n",
       "---\n",
       "\n",
       "### Conclusion\n",
       "The concerns surrounding DeepSeek and the proposed legislation highlight the intersection of technology, national security, and international relations. The high engagement with the topic underscores its significance, as the U.S. grapples with balancing innovation and national interests in the face of growing Chinese AI influence.\n",
       "\n",
       "---\n",
       "\n",
       "### Further Reading\n",
       "\n",
       "**DeepSeek users could face million-dollar fine and prison time under new law**\n",
       "- Source: https://www.the-independent.com/tech/deepseek-ai-us-ban-prison-b2692396.html\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ ACTION: Create analysis\n",
      "üìù RESULT: ‚úÖ Analysis complete for 1 trends\n",
      "\n",
      "==================================================\n",
      "\n",
      "ü§î THINKING: Analysis complete, final report generated\n",
      "\n",
      "‚úÖ ANALYSIS COMPLETE\n",
      "==================================================\n",
      "\n",
      "Final report has been generated in the response.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file in current directory\n",
    "load_dotenv()\n",
    "\n",
    "reddit_creds = {\n",
    "    \"client_id\": os.getenv(\"REDDIT_CLIENT_ID\"),\n",
    "    \"client_secret\": os.getenv(\"REDDIT_CLIENT_SECRET\"), \n",
    "    \"user_agent\": os.getenv(\"REDDIT_USER_AGENT\")\n",
    "}\n",
    "\n",
    "openai_api_key = \"no api needed\" ##switch to openAI key when for OpenAI implementation\n",
    "\n",
    "result = main(reddit_creds, openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
